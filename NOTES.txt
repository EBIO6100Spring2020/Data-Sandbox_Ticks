Tick Data Issues

Major changes to tck_field:

##### 1. Make useful dates #####

Date is currently in “[YYYY]-[MM]-[DD]T[HH]:[MM]Z” format. Keeping this column in because it is a unique time stamp for every sample.
However, I am also adding the following variables:
-year (YYYY) [numeric]
-month (MM) [numeric]
-day (DD) [numeric]
-dayOfYear (DDD) [numeric]

##### 2. SampleID problem ######

The sampleID column is not filled out properly in the tck_field and tck_tax data— there are a lot of blanks in the sampleID column for tck_field, and there are some “incorrect” sampleIDs in both datasets (e.g. a sampleID that says BLAN_012.20180806 is actually collected on 2018-08-07). It looks like the formula for sampleID is supposed to be “plotID.YYYYMMDD”. Therefore, what I did was make a sampleID2 column that follows “plotID.YYYYMMDD”, and then merged sampleID_original [tck_field], sampleID_tax [tck_tax] and sampleID2, allowing original sampleIDs to take precedence. I allowed existing “incorrect” samples to remain because they correspond to (also incorrect) sampleIDs and subsampleIDs in the tck_path and tck_tax datasets. In order for a tck_field row to adopt a tck_tax sampleID, the timestamp and plotID must be identical between the two.  Below are all the “incorrect” sampleID examples that I am referring to. There were no extraordinary remarks in the ‘remarks’ column about any of them. 

	sampleID [tck_field]	sampleID [tck_path]	sampleID2 [created]
1	BLAN_012.20180806	BLAN_012.20180806	BLAN_012.20180807
2	BLAN_012.20180806	BLAN_012.20180806	BLAN_012.20180807
3	SCBI_006.20180730	SCBI_006.20180730	SCBI_006.20180731
4	SCBI_006.20180730	SCBI_006.20180730	SCBI_006.20180731
5	SCBI_039.20180730	SCBI_039.20180730	SCBI_039.20180731
6	SCBI_039.20180730	SCBI_039.20180730	SCBI_039.20180731
7	SCBI_039.20180730	SCBI_039.20180730	SCBI_039.20180731
8	SERC_012.20170809	SERC_012.20170809	SERC_012.20170810
9	SERC_012.20170809	SERC_012.20170809	SERC_012.20170810
10	TREE_019.20180910	TREE_019.20180910	TREE_019.20180911
11	TREE_019.20180910	TREE_019.20180910	TREE_019.20180911
12	TREE_019.20180910	TREE_019.20180910	TREE_019.20180911
13	TREE_019.20180910	TREE_019.20180910	TREE_019.20180911
14	OAES_004.20170403	OAES_004.20170403	OAES_004.20170404
15	OAES_021.20170509	OAES_021.20170509	OAES_021.20170510

##### 3. Remove samples that had flooding, fire, or other "acts of god" #####

Below is a list of all the samples I removed, and the reasons I removed them. I also included other remarks that I felt did NOT warrant removal, though we can change this later if needed.

sampleCondition comments:
    - “Did not take cooler out in the field.”— kept all samples. Who cares! ;)
    - “Distance estimated (described in remarks)”— these are samples that had really bad estimations (aka, lost the data sheet and estimated from memory), but I ended up keeping them in, since drags were supposed to be a certain length anyway:
ORNL_007.20170323
OAES_008.20170620
OSBS_022.20170824
LENO_003.20180717

“Other (described in remarks)” — I removed all samples that said there was flooding, fire, or other impossible sampling scenarios, since this is obviously not going to have ticks, and may zero-inflate our data.
OSBS_022.20160310
LAJA_003.20161214
LAJA_001.20161214
LAJA_002.20161214
LAJA_030.20161215
UKFS_003.20170523
TALL_001.20180522
GRSM_009.20180704

##### 4. Investigate non-unique sampleIDs in tck_field #####

There are 16 samples that were dragged twice. The totalAreaSampled and time stamps are different between duplicate sampleIDs, so it is NOT a true duplicate row; they are almost certainly independent drags. There are no comments in either the “sampleCondition” or “remarks” columns about what happened— some of the “remarks” say different things between the two duplicates, but there is no remark on why there were two drags. Some drags were done by the same person; some drags were done by two different people.

Duplicate drags ranged from minutes (20 min) to hours (8 hours) apart, but most duplicates were between 2-3 hours apart. Further, ALL “first” drags had zero tick occurrences. I hypothesize that the second drag was done to try to get some ticks. There was only one instance where they did end up getting a tick (1 tick) in their second drag. All other second drags resulted in zero ticks. 

Because of this, I am going to delete all SECOND duplicate tick drags. I am not going to merge them because if drags were done in the same location, they would slightly underestimate true tick density in that area (hypothetically), since we are artificially inflating total area sampled (multiplying by two when it was really dragging over the SAME area twice). 


##### 5. Edit and filter tck_tax, tck_field #####

Did the following things for tck_tax:
- Remove compromised samples (3 are sampleCondition!=“OK”)
- Remove non-ticks (sexOrAge==“”)
- Change ageOrSex column to 2 separate columns
- Put in “NA” where we don’t know family, genus, or species

Did the following things for tck_tax:
- Remove all samples with no counts for any life stage

##### 6. Matching counts #####

The counts in tck_field and tck_tax don’t add. up. There is no method to this madness; there are errors across time, location, and tick density (aka it wasn’t just high count data that we saw errors in). So, I went through manually (line by line in some cases) to see what the problem was with each mismatch.

There are a total of 6188 unique sampleIDs. Of these, 5041 (81.5%) were a perfect match in terms of adult, nymph, and larva counts between tck_field and tck_taxonomy (levelError=0). Of the remaining 1077,  457 of them were simply missing some larva counts (levelError=1). I would imagine this was done because larva cannot be easily differentiated taxonomically, so they might have been ignored. I would trust the field data over the taxonomy data in this case.

This leaves 620 (~10%) remaining samples where there was some kind of mix-up between adults, nymphs, and larva counts. For 197 of these samples (3.2% of total samples), the mismatching counts are because they have no tick taxonomies at all— all counts are zero in tck_tax (levelError=2). This lack of data is not specific to any year, location, or month. Also, it is not biased toward large or small sample sizes. Thus, I do not think there will be bias problems if we just remove them. These samples probably represent the natural error rate of losing samples; forgetting/lacking funding to do certain samples; etc.

This leaves 423 samples. For 82 of these, there are actually the same number of total ticks, but the life stage (adult, nymph, larva) counts are shuffled (levelError=3). In this case, I am going to default to tick TAXONOMY counts, because I am assuming that IDing ticks to life stage is easier and more accurate in the lab than in the field. For example, perhaps a few small male ticks were mistaken for a nymph, or a nymph for a larva when counting quickly in the field.

Finally, of the 341 remaining samples there are two main types of errors: either the counts from the field data are greater than counts summed from the taxonomy data; or vice versa. If field counts are greater than taxonomy counts (220 samples), then it is likely the person IDing ticks in the lab simply didn’t ID ALL the ticks (levelError=4).  In most cases, we see that there are many larvae in the field counts, but only 1 or 2 larvae in the taxonomy counts. Therefore, the person IDing to taxonomy probably just got lazy and stopped counting. For these cases, we default to the taxonomy file for adult and nymph counts, but keep the total tick counts ( by supplementing larva counts) from field data. There is only one instance where this seems off (see plot), so we just remove that point all together.

Finally, there were 121 samples where there were actually more ticks in the taxonomy data than the field data. When differences in counts were small (<=10), I am assuming there was a counting error in the field and default to counts from the taxonomy data (levelError=5). However, if count errors were large (>10), or if there was something wrong-looking about the samples, samples were simply discarded (3 samples discarded). The threshold of 10 was determined by cross-checking with the tck_path file to see if they actually tested that many ticks for pathogens. If the number of ticks tested for pathogens was somewhere between the tick counts in the field data and taxonomy data, I assumed that the taxonomy data was actually correct since the tick field data must have been wrong.

For all these changes, I’ve created a column that say “levelError”. Lower numbers mean more confidence in the count accuracy— for example, the 5041 perfect matches are levelError=0. The corresponding “level”s of error are described above, in case you want to manually filter out certain cases of errors. For example, you may decide that you only want non-adjusted counts. In this cause, you’ll filter by levelError==0 so that you only keep the original 5041 perfect matches.

##### 7. Merging taxonomy and field counts #####

Here, I finally combine tick field counts (adjusted, described in #6) and tick taxonomies. Essentially, each tick in the tck_field dataset was assigned an artificial “unique tick ID”, and each tick taxonomy in the tck_tax dataset was also assigned an artificial “unique tick ID”— then, these two were merged. In some cases, there were not enough tick taxonomies for all ticks counted, so these are simply left as “blank”.

##### 8. Merging tick counts/taxonomy with tick pathogen #####

In the MASTER file, each row represents an individual tick. This was done so we can have pathogen data on EACH tick.

Note that both pathogen and taxonomy information is incomplete for datasets, so be very careful when you are summarizing data. For example, if you are interested in abundance of a particular tick species, **sum carefully** because some sites may have hundreds of ticks, but only a few (~10) IDs. Does this mean there are only 10 of those tick species? No! More likely the ID-er got bored after IDing 10 ticks, and gave up because the rest of the ticks all looked the same.

##### 9. Creating subsets and appropriate summaries #####

ALL SPECIES-LEVEL DATASETS  have both RAW (rawCount) and ESTIMATED species counts (estimatedCount). The estimates are calculated by multiplying the RELATIVE ABUNDANCES of species IDs (per lifestage) by TOTAL RAW COUNTS of the sample.
For example:
A sample has 10 adults.  However only 5 of them were ID’d (the rest are NA): they found 1 IXOSCA and 4 AMBAME.
Thus, the final estimated counts for each species are 2 IXOASCA and 8 AMBAME.
“Real” NAs and “Real” zeros are preserved— that is, when there is an NA it actually means that no data was written down, whereas 0 means there were definitely zero observations.

